# This daemonset is only to be used with kind as a workaround of kindest/node
# If you are an end user this is not supported at all.
kind: DaemonSet
apiVersion: apps/v1
metadata:
  name: ovs
  namespace: ovs-kind
  annotations:
    kubernetes.io/description: |
      This daemon set launches the Open vSwitch daemon.
spec:
  selector:
    matchLabels:
      app: ovs
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: ovs
        component: network
        type: infra
        openshift.io/component: network
    spec:
      hostNetwork: true
      priorityClassName: system-node-critical
      containers:
      - name: openvswitch
        image: quay.io/openshift/origin-sdn:latest
        command:
        - /bin/bash
        - -c
        - |
          #!/bin/bash
          set -euo pipefail

          if [ -f /host/var/run/ovs-config-executed ]; then
            echo "openvswitch is running in systemd"
            # Don't need to worry about restoring flows; this can only change if we've rebooted
            rm /var/run/openvswitch/flows.sh || true

            # patch up any possible permissions issues
            ovs_uid=$(chroot /host id -u openvswitch)
            ovs_gid=$(chroot /host id -g openvswitch)
            chown -R "${ovs_uid}:${ovs_gid}" /run/openvswitch
            exec tail -F /host/var/log/openvswitch/ovs-vswitchd.log /host/var/log/openvswitch/ovsdb-server.log
            # executes forever
          fi

          # if another process is listening on the cni-server socket, wait until it exits
          retries=0
          while true; do
            if /usr/share/openvswitch/scripts/ovs-ctl status &>/dev/null; then
              echo "warning: Another process is currently managing OVS, waiting 15s ..." 2>&1
              sleep 15 & wait
              (( retries += 1 ))
            else
              break
            fi
            if [[ "${retries}" -gt 40 ]]; then
              echo "error: Another process is currently managing OVS, exiting" 2>&1
              exit 1
            fi
          done

          chown -R openvswitch:openvswitch /var/run/openvswitch
          chown -R openvswitch:openvswitch /etc/openvswitch

          function quit {
              # Save the flows
              echo "$(date -u "+%Y-%m-%d %H:%M:%S") info: Saving flows ..." 2>&1
              bridges=$(ovs-vsctl -- --real list-br)
              TMPDIR=/var/run/openvswitch /usr/share/openvswitch/scripts/ovs-save save-flows $bridges > /var/run/openvswitch/flows.sh
              echo "$(date -u "+%Y-%m-%d %H:%M:%S") info: Saved flows" 2>&1

              # Don't allow ovs-vswitchd to clear datapath flows on exit
              kill -9 $(cat /var/run/openvswitch/ovs-vswitchd.pid 2>/dev/null) 2>/dev/null || true
              kill $(cat /var/run/openvswitch/ovsdb-server.pid 2>/dev/null) 2>/dev/null || true
              exit 0
          }
          trap quit SIGTERM

          # launch OVS
          # Start the ovsdb so that we can prep it before we start the ovs-vswitchd
          /usr/share/openvswitch/scripts/ovs-ctl start --ovs-user=openvswitch:openvswitch --no-ovs-vswitchd --system-id=random --no-monitor

          # Set the flow-restore-wait to true so ovs-vswitchd will wait till flows are restored
          ovs-vsctl --no-wait set Open_vSwitch . other_config:flow-restore-wait=true
          
          # Restrict the number of pthreads ovs-vswitchd creates to reduce the
          # amount of RSS it uses on hosts with many cores
          # https://bugzilla.redhat.com/show_bug.cgi?id=1571379
          # https://bugzilla.redhat.com/show_bug.cgi?id=1572797
          if [[ `nproc` -gt 12 ]]; then
              ovs-vsctl --no-wait set Open_vSwitch . other_config:n-revalidator-threads=4
              ovs-vsctl --no-wait set Open_vSwitch . other_config:n-handler-threads=10
          fi

          # And finally start the ovs-vswitchd now the DB is prepped
          /usr/share/openvswitch/scripts/ovs-ctl start --ovs-user=openvswitch:openvswitch --no-ovsdb-server --system-id=random --no-monitor

          # Load any flows that we saved
          echo "$(date -u "+%Y-%m-%d %H:%M:%S") info: Loading previous flows ..." 2>&1
          if [[ -f /var/run/openvswitch/flows.sh ]]; then
             echo "$(date -u "+%Y-%m-%d %H:%M:%S") info: Adding br0 if it doesn't exist ..." 2>&1
             /usr/bin/ovs-vsctl --may-exist add-br br0 -- set Bridge br0 fail_mode=secure protocols=OpenFlow13
             echo "$(date -u "+%Y-%m-%d %H:%M:%S") info: Created br0, now adding flows ..." 2>&1
             mv /var/run/openvswitch/flows.sh /var/run/openvswitch/flows-old.sh
             sh -x /var/run/openvswitch/flows-old.sh
             echo "$(date -u "+%Y-%m-%d %H:%M:%S") info: Done restoring the existing flows ..." 2>&1
             rm /var/run/openvswitch/flows-old.sh
          fi
          
          echo "$(date -u "+%Y-%m-%d %H:%M:%S") info: Remove other config ..." 2>&1
          ovs-vsctl --no-wait --if-exists remove Open_vSwitch . other_config flow-restore-wait=true
          echo "$(date -u "+%Y-%m-%d %H:%M:%S") info: Removed other config ..." 2>&1

          tail -F --pid=$(cat /var/run/openvswitch/ovs-vswitchd.pid) /var/log/openvswitch/ovs-vswitchd.log &
          tail -F --pid=$(cat /var/run/openvswitch/ovsdb-server.pid) /var/log/openvswitch/ovsdb-server.log &
          wait
        securityContext:
          privileged: true
        volumeMounts:
        - mountPath: /lib/modules
          name: host-modules
          readOnly: true
        - mountPath: /run/openvswitch
          name: host-run-ovs
        - mountPath: /var/run/openvswitch
          name: host-run-ovs
        - mountPath: /sys
          name: host-sys
          readOnly: true
        - mountPath: /host
          name: host-slash
          readOnly: true
        - mountPath: /etc/openvswitch
          name: host-config-openvswitch
        resources:
          requests:
            cpu: 100m
            memory: 400Mi
        livenessProbe:
          exec:
            command:
            # Validate that ovs-vswitchd and ovsdb are running. Check that
            # 1. that ovs-vswitchd is responding to queries
            # 2. that ovsdb is responding to queries
            #
            # Don't bother executing this if we're in systemd, as the liveness
            # probe isn't helpful.
            - /bin/bash
            - -c
            - |
              #!/bin/bash
              if [ -f /host/var/run/ovs-config-executed ]; then
                exit 0
              fi
              /usr/bin/ovs-appctl -T 5 ofproto/list > /dev/null &&
              /usr/bin/ovs-vsctl -t 5 show > /dev/null
          initialDelaySeconds: 15
          periodSeconds: 5
          timeoutSeconds: 21
        readinessProbe:
          exec:
            command:
            # The same validation as above.
            #
            # Need the manual target file because ovs-appctl doesn't like
            # being in a different namespace from ovs-vswitchd, which happens
            # if ovs is running in systemd.
            - /bin/bash
            - -c
            - |
              #!/bin/bash
              PID=$(cat /var/run/openvswitch/ovs-vswitchd.pid)
              /usr/bin/ovs-appctl -t "/var/run/openvswitch/ovs-vswitchd.${PID}.ctl" -T 5 ofproto/list > /dev/null &&
              /usr/bin/ovs-vsctl -t 5 show > /dev/null
          initialDelaySeconds: 15
          periodSeconds: 5
          timeoutSeconds: 11
      volumes:
      - name: host-modules
        hostPath:
          path: /lib/modules
      - name: host-run-ovs
        hostPath:
          path: /run/openvswitch
      - name: host-sys
        hostPath:
          path: /sys
      - name: host-config-openvswitch
        hostPath:
          path: /var/lib/openvswitch
      - name: host-slash
        hostPath:
          path: /
      tolerations:
      - operator: "Exists"
