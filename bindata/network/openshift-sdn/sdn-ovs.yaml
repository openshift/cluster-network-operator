{{if .InstallOVS}}
kind: DaemonSet
apiVersion: apps/v1
metadata:
  name: ovs
  namespace: openshift-sdn
  annotations:
    kubernetes.io/description: |
      This daemon set launches the Open vSwitch daemon.
    release.openshift.io/version: "{{.ReleaseVersion}}"
spec:
  selector:
    matchLabels:
      app: ovs
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: ovs
        component: network
        type: infra
        openshift.io/component: network
    spec:
      serviceAccountName: sdn #needed to run privileged pods; not used for api access
      hostNetwork: true
      priorityClassName: system-node-critical
      containers:
      - name: openvswitch
        image: {{.SDNImage}}
        command:
        - /bin/bash
        - -c
        - |
          #!/bin/bash
          set -euo pipefail
          export SYSTEMD_IGNORE_CHROOT=yes

          # systemctl cannot be used in a separate PID namespace to reach
          # the systemd running in PID 1. Therefore we need to use the dbus API
          systemctl_restart(){
            gdbus call \
              --system \
              --dest org.freedesktop.systemd1 \
              --object-path /org/freedesktop/systemd1/unit/"$(svc_encode_name ${1})"_2eservice \
              --method org.freedesktop.systemd1.Unit.Restart "replace"
          }
          svc_encode_name(){
            # systemd encodes some characters, so far we only need to encode
            # the character "-" but there may be more in the future.
            echo "${1//-/_2d}"
          }

            # In some very strange corner cases, the owner for /run/openvswitch
            # can be wrong, so we need to clean up and restart.
            ovs_uid=$(chroot /host id -u openvswitch)
            ovs_gid=$(chroot /host id -g openvswitch)
            chown -R "${ovs_uid}:${ovs_gid}" /run/openvswitch
            if [[ ! -S /run/openvswitch/db.sock ]]; then
              systemctl_restart ovsdb-server
            fi
            # We need to explicitly exit on SIGTERM, see https://github.com/openshift/cluster-dns-operator/issues/65
            function quit {
                exit 0
            }
            trap quit SIGTERM
            # Don't need to worry about restoring flows; this can only change if we've rebooted
            tail --pid=$BASHPID -F /host/var/log/openvswitch/ovs-vswitchd.log /host/var/log/openvswitch/ovsdb-server.log &
            wait
        securityContext:
          privileged: true
        volumeMounts:
        - mountPath: /lib/modules
          name: host-modules
          readOnly: true
        - mountPath: /run
          name: host-run
        - mountPath: /sys
          name: host-sys
          readOnly: true
        - mountPath: /etc/openvswitch
          name: host-config-openvswitch
        - mountPath: /host
          name: host-slash
          readOnly: true
        resources:
          requests:
            cpu: 15m
            memory: 400Mi
        terminationMessagePolicy: FallbackToLogsOnError
        terminationGracePeriodSeconds: 45
      nodeSelector:
        kubernetes.io/os: linux
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: network.operator.openshift.io/external-openvswitch
                operator: DoesNotExist
      volumes:
      - name: host-modules
        hostPath:
          path: /lib/modules
      - name: host-run
        hostPath:
          path: /run
      - name: host-sys
        hostPath:
          path: /sys
      - name: host-config-openvswitch
        hostPath:
          path: /var/lib/openvswitch
          type: DirectoryOrCreate
      - name: host-slash
        hostPath:
          path: /
      tolerations:
      - operator: "Exists"
{{- end}}
