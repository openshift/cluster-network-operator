apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: sdn-controller
  namespace: openshift-sdn
  annotations:
    kubernetes.io/description: |
      This deployment runs the openshift SDN networking controller.
    release.openshift.io/version: "{{.ReleaseVersion}}"
  labels:
    app: sdn-controller
spec:
  selector:
    matchLabels:
      app: sdn-controller
  template:
    metadata:
      labels:
        app: sdn-controller
    spec:
      containers:
      - name: sdn-controller
        image: {{.HypershiftImage}}
        command: ["hypershift", "openshift-network-controller"]
        resources:
          requests:
            cpu: 10m
            memory: 50Mi
        env:
        # TODO: bind-mount the kubelet's kubeconfig like the openshift-sdn process
        # need to get the `oc` binary in to the hypershift image first
        - name: KUBERNETES_SERVICE_PORT # allows the controller to communicate with apiserver directly on same host.
          value: "{{.KUBERNETES_SERVICE_PORT}}"
        - name: KUBERNETES_SERVICE_HOST # allows the controller to communicate with apiserver directly on same host.
          value: "{{.KUBERNETES_SERVICE_HOST}}"
        terminationMessagePolicy: FallbackToLogsOnError
      hostNetwork: true
      nodeSelector:
        node-role.kubernetes.io/master: ""
      priorityClassName: "system-cluster-critical"
      restartPolicy: Always
      serviceAccountName: sdn-controller
      securityContext:
        runAsNonRoot: true
        runAsUser: 65534
      tolerations:
      - key: "node-role.kubernetes.io/master"
        operator: "Exists"
        effect: "NoSchedule"
      - key: "node.kubernetes.io/not-ready"
        operator: "Exists"
        effect: "NoSchedule"
